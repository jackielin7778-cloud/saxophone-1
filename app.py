import streamlit as st
import pandas as pd
import time
import random
import re
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
from io import BytesIO

# --- åˆå§‹åŒ–è¨­å®š ---
st.set_page_config(page_title="è–©å…‹æ–¯é¢¨å¹å˜´å¸‚å ´èª¿æŸ¥ç³»çµ±", layout="wide")

if 'url_list' not in st.session_state:
    st.session_state.url_list = []

def get_driver():
    """åˆå§‹åŒ–é›²ç«¯ç’°å¢ƒå°ˆç”¨çš„ Chrome Driver"""
    chrome_options = Options()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--disable-gpu")
    # å½è£æˆçœŸäººç€è¦½å™¨
    chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    
    # è‡ªå‹•å®‰è£ä¸¦å•Ÿå‹• Driver
    service = Service(ChromeDriverManager().install())
    return webdriver.Chrome(service=service, options=chrome_options)

def scrape_data(urls):
    all_data = []
    driver = get_driver()
    
    progress_bar = st.progress(0)
    for index, url in enumerate(urls):
        try:
            driver.get(url)
            # éš¨æ©Ÿå»¶é² 5-10 ç§’ï¼Œå°æŠ—é›»å•†åµæ¸¬
            time.sleep(random.uniform(5, 10)) 
            
            # ç²å–é é¢æ¨™é¡Œèˆ‡å…§å®¹
            page_title = driver.title
            page_source = driver.page_source
            
            # --- è³£æ–¹åç¨±è§£æ ---
            # è¦çš®èˆ‡ Yahoo çµæ§‹å¸¸è®Šï¼Œé€™è£¡ä½¿ç”¨æ›´å…·å½ˆæ€§çš„å°‹æ‰¾æ–¹å¼
            seller_name = "æœªçŸ¥è³£å®¶"
            if "shopee" in url:
                platform = "è¦çš®"
                try:
                    # å˜—è©¦æŠ“å–è¦çš®è³£å ´åç¨±å¸¸ç”¨æ¨™ç±¤
                    seller_element = driver.find_element(By.CSS_SELECTOR, 'div.V67tSj, span.official-shop-label__name, ._23_19X')
                    seller_name = seller_element.text
                except:
                    seller_name = "éœ€æ‰‹å‹•æª¢æŸ¥(è¢«é˜»æ“‹)"
            else:
                platform = "Yahooæ‹è³£"
                try:
                    seller_element = driver.find_element(By.CSS_SELECTOR, '.yui3-u-1 .name, .seller-name')
                    seller_name = seller_element.text
                except:
                    seller_name = "éœ€æ‰‹å‹•æª¢æŸ¥"

            # --- å”®åƒ¹è§£æ ---
            price = "åƒ¹æ ¼æœªå®š"
            try:
                # å°‹æ‰¾åŒ…å« $ ç¬¦è™Ÿæˆ–æ•¸å­—çš„åƒ¹æ ¼å€å¡Š
                price_match = re.search(r'\$\s*[0-9,]+', page_source)
                if price_match:
                    price = price_match.group()
            except:
                pass

            # --- é©ç”¨æ¨‚å™¨ (é—œéµå­—æƒæ) ---
            instrument = "ä¸é™/æœªçŸ¥"
            content_lower = page_source.lower()
            if any(k in content_lower for k in ["alto", "ä¸­éŸ³"]):
                instrument = "ä¸­éŸ³Alto"
            elif any(k in content_lower for k in ["tenor", "æ¬¡ä¸­éŸ³"]):
                instrument = "æ¬¡ä¸­éŸ³Tenor"
            elif any(k in content_lower for k in ["soprano", "é«˜éŸ³"]):
                instrument = "é«˜éŸ³Soprano"

            all_data.append({
                "ä¾†æºå¹³å°": platform,
                "è³£æ–¹åç¨±": seller_name,
                "é©ç”¨æ¨‚å™¨": instrument,
                "å”®åƒ¹": price,
                "å•†å“ç¶²å€": url
            })
        except Exception as e:
            st.error(f"ç¶²å€è§£æå¤±æ•—: {url}")
        
        progress_bar.progress((index + 1) / len(urls))
    
    driver.quit()
    return pd.DataFrame(all_data)

# --- Streamlit UI ---
st.title("ğŸ· è–©å…‹æ–¯é¢¨å¹å˜´å¸‚å ´èª¿æŸ¥ç³»çµ± (é›²ç«¯ä¿®å¾©ç‰ˆ)")

# ç¶²å€è¼¸å…¥å€åŸŸ
with st.form("url_input_form", clear_on_submit=True):
    new_url = st.text_input("è«‹è¼¸å…¥è¦çš®æˆ– Yahoo å•†å“ç¶²å€ï¼š")
    submitted = st.form_submit_button("æ–°å¢èª¿æŸ¥ç¶²å€")
    if submitted and new_url:
        if new_url not in st.session_state.url_list:
            st.session_state.url_list.append(new_url)
            st.success("ç¶²å€å·²æˆåŠŸåŠ å…¥æ¸…å–®ï¼")

# é¡¯ç¤ºèˆ‡æ“ä½œ
if st.session_state.url_list:
    st.write(f"ç›®å‰ç›£æ§ä¸­æ•¸é‡ï¼š{len(st.session_state.url_list)}")
    with st.expander("æŸ¥çœ‹æ‰€æœ‰ç¶²å€"):
        for u in st.session_state.url_list:
            st.text(u)

    col1, col2 = st.columns(2)
    with col1:
        if st.button("ğŸš€ é–‹å§‹çˆ¬å–"):
            df = scrape_data(st.session_state.url_list)
            if not df.empty:
                st.session_state.results = df
                st.dataframe(df)
    
    with col2:
        if st.button("ğŸ§¹ æ¸…ç©ºç¶²å€"):
            st.session_state.url_list = []
            st.rerun()

    # ä¸‹è¼‰å€åŸŸ
    if 'results' in st.session_state:
        output = BytesIO()
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            st.session_state.results.to_excel(writer, index=False)
        st.download_button(
            label="ğŸ“¥ ä¸‹è¼‰ Excel å ±è¡¨",
            data=output.getvalue(),
            file_name="sax_mouthpiece_survey.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
