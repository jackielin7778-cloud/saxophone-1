import streamlit as st
import pandas as pd
import time
import random
import re
import os
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from io import BytesIO

# --- 1. é é¢é…ç½® ---
st.set_page_config(page_title="ğŸ· è–©å…‹æ–¯é¢¨å¹å˜´æœå°‹å…¨æ•¸æ‹”å›", layout="wide")

def get_driver():
    chrome_options = Options()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
    chrome_options.add_experimental_option('useAutomationExtension', False)
    chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36")
    
    for path in ["/usr/bin/chromium", "/usr/bin/chromium-browser"]:
        if os.path.exists(path):
            chrome_options.binary_location = path
            break
            
    service = Service("/usr/bin/chromedriver") if os.path.exists("/usr/bin/chromedriver") else Service()
    driver = webdriver.Chrome(service=service, options=chrome_options)
    driver.execute_cdp_cmd("Page.addScriptToEvaluateOnNewDocument", {
        "source": "Object.defineProperty(navigator, 'webdriver', {get: () => undefined})"
    })
    return driver

def identify_brand(title):
    """å“ç‰Œè­˜åˆ¥é‚è¼¯"""
    brands = {
        "Selmer": ["selmer", "å¡çˆ¾ç‘ª", "s80", "s90"],
        "Vandoren": ["vandoren", "å‡¡å¤šå€«", "è¬å¤šæ—"],
        "Yanagisawa": ["yanagisawa", "æŸ³æ¾¤"],
        "Meyer": ["meyer"],
        "Yamaha": ["yamaha", "å±±è‘‰"],
        "JodyJazz": ["jodyjazz", "jody jazz"],
        "Otto Link": ["otto link", "ottolink"],
        "D'Addario": ["d'addario", "daddario"],
        "Beechler": ["beechler"],
        "Theo Wanne": ["theo wanne"],
        "Berg Larsen": ["berg larsen"]
    }
    t_lower = title.lower()
    for brand, keywords in brands.items():
        if any(k in t_lower for k in keywords):
            return brand
    return "å…¶ä»–/è‡ªè£½"

def scrape_search_page(url):
    all_items = []
    log_placeholder = st.empty()
    logs = []

    def log(msg):
        logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] {msg}")
        log_placeholder.code("\n".join(logs[-10:]))

    try:
        driver = get_driver()
        log("ğŸš€ ç€è¦½å™¨é€²å…¥æœå°‹é é¢...")
        driver.get(url)
        
        # æ¨¡æ“¬äººé¡å‘ä¸‹æ»¾å‹•è¼‰å…¥åœ–ç‰‡èˆ‡å…§å®¹
        for _ in range(2):
            driver.execute_script("window.scrollBy(0, 1000);")
            time.sleep(2)
        
        # å¤šé‡ CSS æ¢é‡
        selectors = [
            'li[data-item-id]',
            'div[class*="BaseItem"]',
            'ul[class*="GeneralList"] li',
            '.sc-762bc2d0-0'
        ]
        
        items = []
        for s in selectors:
            items = driver.find_elements(By.CSS_SELECTOR, s)
            if len(items) > 5:
                log(f"ğŸ¯ æ¢é‡æˆåŠŸ: ä½¿ç”¨ [{s}] æŠ“å–")
                break
        
        if not items:
            log("âš ï¸ ä½¿ç”¨ä¿åº•æŠ“å–æ¨¡å¼...")
            items = driver.find_elements(By.XPATH, "//div[contains(@class, 'item') or contains(@class, 'product')]")

        log(f"ğŸ“¦ åµæ¸¬åˆ° {len(items)} å€‹æ½›åœ¨å•†å“å€å¡Š")

        for item in items:
            try:
                # å–å¾—æ•´å¡Šæ–‡å­—é€²è¡Œè§£æ
                raw_text = item.text.strip()
                if not raw_text or "$" not in raw_text:
                    continue
                
                # 1. è§£ææ¨™é¡Œ (é€šå¸¸æ˜¯ç¬¬ä¸€è¡Œæˆ–æœ€é•·çš„ä¸€æ®µ)
                lines = [line.strip() for line in raw_text.split('\n') if line.strip()]
                title = lines[0] if lines else "ç„¡æ¨™é¡Œ"
                
                # 2. è§£æåƒ¹æ ¼
                price_match = re.search(r'\$\s*[0-9,]+', raw_text)
                price = price_match.group() if price_match else "N/A"
                
                # 3. åˆ¤æ–·æ¨‚å™¨
                t_lower = title.lower()
                instrument = "å…¶ä»–"
                if "alto" in t_lower or "ä¸­éŸ³" in t_lower: instrument = "ä¸­éŸ³Alto"
                elif "tenor" in t_lower or "æ¬¡ä¸­éŸ³" in t_lower: instrument = "æ¬¡ä¸­éŸ³Tenor"
                elif "soprano" in t_lower or "é«˜éŸ³" in t_lower: instrument = "é«˜éŸ³Soprano"
                
                # 4. å“ç‰Œè­˜åˆ¥
                brand = identify_brand(title)
                
                # 5. è³£å®¶è­˜åˆ¥ (å˜—è©¦å¾æœ€å¾Œå¹¾è¡Œæ‰¾)
                seller = "å•†å®¶"
                if len(lines) > 2:
                    # å°‹æ‰¾ä¸åŒ…å« $ ä¸”è¼ƒçŸ­çš„è¡Œä½œç‚ºè³£å®¶å
                    for l in reversed(lines):
                        if "$" not in l and len(l) < 15:
                            seller = l
                            break

                all_items.append({
                    "å“ç‰Œ": brand,
                    "è³£æ–¹åç¨±": seller,
                    "å•†å“è³‡è¨Š": title,
                    "é©ç”¨æ¨‚å™¨": instrument,
                    "å”®åƒ¹": price
                })
            except:
                continue

        # è½‰æˆ DataFrame ä¸¦ç§»é™¤é‡è¤‡é …
        df = pd.DataFrame(all_items).drop_duplicates()
        log(f"âœ… æˆåŠŸæ‹”å› {len(df)} ç­†æ•¸æ“š")
        driver.quit()
        return df

    except Exception as e:
        log(f"âŒ ç•°å¸¸: {str(e)}")
        if 'driver' in locals(): driver.quit()
        return pd.DataFrame()

# --- UI ä»‹é¢ ---
st.title("ğŸ· è–©å…‹æ–¯é¢¨å¹å˜´æœå°‹ã€Œå…¨æ•¸æ‹”å›ã€ç³»çµ±")
url_input = st.text_input("è¼¸å…¥ Yahoo æœå°‹çµæœç¶²å€ï¼š", placeholder="https://tw.bid.yahoo.com/search/auction/product?p=...")

if st.button("ğŸš€ åŸ·è¡Œå…¨é æ‹”å›"):
    if url_input:
        res = scrape_search_page(url_input)
        if not res.empty:
            st.session_state.final_res = res
            st.dataframe(res, use_container_width=True)

if 'final_res' in st.session_state:
    output = BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        st.session_state.final_res.to_excel(writer, index=False)
    st.download_button("ğŸ“¥ ä¸‹è¼‰ Excel èª¿æŸ¥å ±å‘Š", output.getvalue(), "sax_market_report.xlsx")
