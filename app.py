import streamlit as st
import pandas as pd
import time
import random
import re
import os
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from io import BytesIO

# --- 1. é é¢é…ç½® ---
st.set_page_config(page_title="ğŸ· å¹å˜´èª¿æŸ¥ï¼šåœ°æ¯¯å¼æƒæ", layout="wide")

def get_driver():
    chrome_options = Options()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument(f"--window-size=1920,3000")
    chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
    chrome_options.add_argument("--disable-blink-features=AutomationControlled")
    chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36")
    
    for path in ["/usr/bin/chromium", "/usr/bin/chromium-browser"]:
        if os.path.exists(path):
            chrome_options.binary_location = path
            break
            
    service = Service("/usr/bin/chromedriver") if os.path.exists("/usr/bin/chromedriver") else Service()
    driver = webdriver.Chrome(service=service, options=chrome_options)
    driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
    return driver

def scrape_booth_carpet_scan(base_url):
    all_items = []
    log_placeholder = st.empty()
    logs = []

    def log(msg):
        logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] {msg}")
        log_placeholder.code("\n".join(logs[-10:]))

    # å¼·åˆ¶é‡æ§‹ URL
    clean_url = base_url.split('?')[0].rstrip('/')
    target_url = f"{clean_url}/search/auction/product?p=å¹å˜´"

    try:
        driver = get_driver()
        log(f"ğŸ•µï¸ åœ°æ¯¯å¼æœç´¢å•Ÿå‹•: {target_url}")
        driver.get(target_url)
        time.sleep(12) # å¢åŠ ç©©å®šæ€§

        # æš´åŠ›æ»¾å‹•
        driver.execute_script("window.scrollTo(0, 2000);")
        time.sleep(3)

        # --- æ ¸å¿ƒé‚è¼¯ï¼šåœ°æ¯¯å¼æƒæ ---
        log("ğŸ” æ­£åœ¨è§£æ 27 å€‹æ½›åœ¨ç¯€é»å…§å®¹...")
        
        # æŠ“å–æ‰€æœ‰å¯èƒ½çš„å•†å“å®¹å™¨ (Yahoo Booth å¸¸ç”¨çµæ§‹)
        containers = driver.find_elements(By.CSS_SELECTOR, 'li[data-item-id], [class*="Item__itemContainer"], [class*="BaseItem"]')
        
        if not containers:
            # å¦‚æœæ‰¾ä¸åˆ°å®¹å™¨ï¼Œç›´æ¥æŠ“å–æ‰€æœ‰ A æ¨™ç±¤
            containers = driver.find_elements(By.XPATH, "//a[contains(., '$') or contains(., 'å¹å˜´')]")

        brand_list = ["Selmer", "Vandoren", "Yanagisawa", "Meyer", "Yamaha", "Otto Link", "Beechler", "JodyJazz"]

        for idx, el in enumerate(containers):
            try:
                # æŠ“å–è©²å€å¡Šå…§æ‰€æœ‰æ–‡å­—
                full_text = el.text.strip().replace("\n", " ")
                
                # å˜—è©¦æŠ“å–æ¨™é¡Œ (å¾ Title å±¬æ€§æˆ– Aria-label æˆ–æ–‡å­—å…§å®¹)
                title = ""
                try:
                    title_el = el.find_element(By.TAG_NAME, "a")
                    title = title_el.get_attribute("title") or title_el.get_attribute("aria-label") or title_el.text
                    link = title_el.get_attribute("href")
                except:
                    title = full_text[:60]
                    link = target_url

                # å¦‚æœæ¨™é¡Œé‚„æ˜¯ç©ºçš„æˆ–å¤ªçŸ­ï¼Œè·³é
                if len(title) < 5: continue

                # åƒ¹æ ¼æŠ“å– (æ­£å‰‡è¡¨é”å¼)
                p_match = re.search(r'\$\s*[0-9,]+', full_text)
                price = p_match.group() if p_match else "éœ€é»æ“Šç¶²å€ç¢ºèª"
                
                # å“ç‰Œèˆ‡æ¨‚å™¨åˆ¤å®š
                brand = "å…¶ä»–"
                for b in brand_list:
                    if b.lower() in title.lower():
                        brand = b
                        break
                
                instrument = "å…¶ä»–"
                if any(k in title.lower() for k in ["alto", "ä¸­éŸ³"]): instrument = "ä¸­éŸ³Alto"
                elif any(k in title.lower() for k in ["tenor", "æ¬¡ä¸­éŸ³"]): instrument = "æ¬¡ä¸­éŸ³Tenor"

                all_items.append({
                    "å“ç‰Œ": brand,
                    "å•†å“è³‡è¨Š": title,
                    "é©ç”¨æ¨‚å™¨": instrument,
                    "å”®åƒ¹": price,
                    "ç¶²å€": link
                })
            except Exception as e:
                continue

        df = pd.DataFrame(all_items).drop_duplicates(subset=['å•†å“è³‡è¨Š'])
        log(f"âœ… å®Œæˆï¼æˆåŠŸå¾ 27 å€‹ç¯€é»ä¸­æå–å‡º {len(df)} ç­†æœ‰æ•ˆå•†å“ã€‚")
        driver.quit()
        return df
    except Exception as e:
        log(f"âŒ ç•°å¸¸: {str(e)}")
        if 'driver' in locals(): driver.quit()
        return pd.DataFrame()

# --- UI ä»‹é¢ ---
st.title("ğŸ· è–©å…‹æ–¯é¢¨å¹å˜´ï¼šåœ°æ¯¯å¼èª¿æŸ¥ç³»çµ±")
store_url = st.text_input("åº—å®¶ç¶²å€ï¼š", value="https://tw.bid.yahoo.com/booth/Y9133606367")

if st.button("ğŸš€ å•Ÿå‹•æƒæ"):
    if store_url:
        results = scrape_booth_carpet_scan(store_url)
        if not results.empty:
            st.session_state.booth_res = results
            st.dataframe(results, use_container_width=True)
        else:
            st.error("æƒæå¤±æ•—ã€‚é€™é€šå¸¸æ˜¯æ¨™ç±¤é¸å–å™¨å®Œå…¨å°ä¸ä¸Šã€‚è«‹ç¢ºä¿ç¶²å€æ˜¯æ­£ç¢ºçš„åº—å®¶é é¢ã€‚")

if 'booth_res' in st.session_state:
    output = BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        st.session_state.booth_res.to_excel(writer, index=False)
    st.download_button("ğŸ“¥ ä¸‹è¼‰ Excel å ±å‘Š", output.getvalue(), "sax_carpet_report.xlsx")
