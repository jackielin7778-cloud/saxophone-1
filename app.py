import streamlit as st
import pandas as pd
import time
import random
import re
import os
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from io import BytesIO

st.set_page_config(page_title="ğŸ· å¹å˜´èª¿æŸ¥ï¼šåŸå§‹ç¢¼æš´åŠ›æƒæ", layout="wide")

def get_driver():
    chrome_options = Options()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument(f"--window-size=1920,5000")
    chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
    chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36")
    
    for path in ["/usr/bin/chromium", "/usr/bin/chromium-browser"]:
        if os.path.exists(path):
            chrome_options.binary_location = path
            break
            
    service = Service("/usr/bin/chromedriver") if os.path.exists("/usr/bin/chromedriver") else Service()
    driver = webdriver.Chrome(service=service, options=chrome_options)
    return driver

def scrape_source_code_scan(base_url):
    all_items = []
    log_placeholder = st.empty()
    logs = []

    def log(msg):
        logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] {msg}")
        log_placeholder.code("\n".join(logs[-8:]))

    clean_url = base_url.split('?')[0].rstrip('/')
    target_url = f"{clean_url}/search/auction/product?p=å¹å˜´"

    try:
        driver = get_driver()
        log(f"ğŸ•µï¸ æš´åŠ›æƒæå•Ÿå‹•: {target_url}")
        driver.get(target_url)
        
        # å¼·åˆ¶ç­‰å¾…èˆ‡å¤šæ¬¡æ·±åº¦æ»¾å‹•ï¼Œç¢ºä¿ JavaScript åŸ·è¡Œå®Œç•¢
        for i in range(5):
            driver.execute_script(f"window.scrollTo(0, {i * 1000});")
            time.sleep(3)

        source = driver.page_source
        log(f"ğŸ“¦ åŸå§‹ç¢¼é•·åº¦: {len(source)} å­—å…ƒï¼Œé–‹å§‹æ­£å‰‡è§£æ...")

        # --- æ­£å‰‡è¡¨é”å¼ï¼šç›´æ¥å¾ JSON æ•¸æ“šæˆ–æ¨™ç±¤å±¬æ€§ä¸­æŒ–å– ---
        # å°‹æ‰¾åŒ…å«ã€Œå¹å˜´ã€çš„æ¨™é¡Œã€åƒ¹æ ¼ä»¥åŠå•†å“ ID çš„æ¨¡å¼
        # é€™æ˜¯ Yahoo 2026 å¹´åº•å±¤æ•¸æ“šå¸¸ç”¨çš„ JSON çµæ§‹ç‰¹å¾µ
        patterns = [
            # æ¨¡å¼ 1: æŠ“å–æ¨™é¡Œèˆ‡åƒ¹æ ¼ (é‡å°å‹•æ…‹åŠ è¼‰çš„ JSON å€å¡Š)
            r'\"title\":\"([^\"]*å¹å˜´[^\"]*)\".*?\"ecPrice\":\"(\d+)\"',
            # æ¨¡å¼ 2: é‡å° HTML å±¬æ€§çš„ä¿åº•æŠ“å–
            r'title=\"([^\"]*å¹å˜´[^\"]*)\".*?\$([0-9,]+)'
        ]

        brand_list = ["Selmer", "Vandoren", "Yanagisawa", "Meyer", "Yamaha", "Otto Link", "Beechler", "JodyJazz"]

        for pattern in patterns:
            matches = re.findall(pattern, source)
            for title, price in matches:
                brand = "å…¶ä»–"
                for b in brand_list:
                    if b.lower() in title.lower():
                        brand = b
                        break
                
                instrument = "å…¶ä»–"
                if any(k in title.lower() for k in ["alto", "ä¸­éŸ³"]): instrument = "ä¸­éŸ³Alto"
                elif any(k in title.lower() for k in ["tenor", "æ¬¡ä¸­éŸ³"]): instrument = "æ¬¡ä¸­éŸ³Tenor"

                all_items.append({
                    "å“ç‰Œ": brand,
                    "å•†å“è³‡è¨Š": title,
                    "é©ç”¨æ¨‚å™¨": instrument,
                    "å”®åƒ¹": f"${price}",
                    "ç¶²å€": target_url # æš´åŠ›æƒæè¼ƒé›£ç²¾æº–åŒ¹é…å€‹åˆ¥ç¶²å€ï¼Œå…ˆçµ¦äºˆæœå°‹é ç¶²å€
                })

        df = pd.DataFrame(all_items).drop_duplicates(subset=['å•†å“è³‡è¨Š'])
        log(f"âœ… æš´åŠ›æƒæå®Œæˆï¼æˆåŠŸæå–å‡º {len(df)} ç­†å•†å“ã€‚")
        driver.quit()
        return df
    except Exception as e:
        log(f"âŒ ç•°å¸¸: {str(e)}")
        if 'driver' in locals(): driver.quit()
        return pd.DataFrame()

# UI ä»‹é¢
st.title("ğŸ· å¹å˜´èª¿æŸ¥ï¼šåŸå§‹ç¢¼æš´åŠ›æƒæç‰ˆ")
store_url = st.text_input("åº—å®¶ç¶²å€ï¼š", value="https://tw.bid.yahoo.com/booth/Y9133606367")

if st.button("ğŸš€ å•Ÿå‹•æš´åŠ›èª¿æŸ¥"):
    if store_url:
        results = scrape_source_code_scan(store_url)
        if not results.empty:
            st.session_state.brute_res = results
            st.dataframe(results, use_container_width=True)
        else:
            st.error("æš´åŠ›æƒæä¹Ÿå¤±æ•—ã€‚é€™ä»£è¡¨è©²åº—å®¶åœ¨é›²ç«¯ç’°å¢ƒä¸‹å®Œå…¨å°é–äº†å…§å®¹æ¸²æŸ“ã€‚")

if 'brute_res' in st.session_state:
    output = BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        st.session_state.brute_res.to_excel(writer, index=False)
    st.download_button("ğŸ“¥ ä¸‹è¼‰ Excel å ±å‘Š", output.getvalue(), "sax_brute_report.xlsx")
