import streamlit as st
import pandas as pd
import time
import random
import re
import os
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from io import BytesIO

st.set_page_config(page_title="ğŸ· å¹å˜´èª¿æŸ¥ï¼šè¡Œå‹•ç‰ˆå½è£çªç ´", layout="wide")

def get_driver():
    chrome_options = Options()
    chrome_options.add_argument("--headless=new")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--disable-gpu")
    
    # --- è¡Œå‹•ç‰ˆå½è£ï¼šæ¨¡æ“¬ iPhone 14 ---
    mobile_ua = "Mozilla/5.0 (iPhone; CPU iPhone OS 16_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.6 Mobile/15E148 Safari/604.1"
    chrome_options.add_argument(f"user-agent={mobile_ua}")
    chrome_options.add_argument("--window-size=390,844") # iPhone è¢å¹•å°ºå¯¸
    
    # æŠ¹é™¤è‡ªå‹•åŒ–ç‰¹å¾µ
    chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
    chrome_options.add_experimental_option('useAutomationExtension', False)
    chrome_options.add_argument("--disable-blink-features=AutomationControlled")

    for path in ["/usr/bin/chromium", "/usr/bin/chromium-browser"]:
        if os.path.exists(path):
            chrome_options.binary_location = path
            break
            
    service = Service("/usr/bin/chromedriver") if os.path.exists("/usr/bin/chromedriver") else Service()
    driver = webdriver.Chrome(service=service, options=chrome_options)
    
    # æ³¨å…¥è¡Œå‹•ç«¯è§¸æ§èˆ‡ WebDriver æŠ¹é™¤
    driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
    return driver

def scrape_mobile_attempt(base_url):
    all_items = []
    log_placeholder = st.empty()
    logs = []

    def log(msg):
        logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] {msg}")
        log_placeholder.code("\n".join(logs[-8:]))

    # --- é—œéµï¼šå¼·åˆ¶è½‰æ›ç‚ºè¡Œå‹•ç‰ˆç¶²å€ ---
    # ç¯„ä¾‹ï¼šhttps://tw.bid.yahoo.com/booth/Y9133606367 -> https://tw.bid.yahoo.com/booth/Y9133606367
    # Yahoo çš„è¡Œå‹•ç‰ˆæœ‰æ™‚æœƒè‡ªå‹•è·³è½‰ï¼Œæˆ‘å€‘æ‰‹å‹•ç¢ºä¿è·¯å¾‘åŒ…å«åº—å…§æœå°‹
    clean_url = base_url.split('?')[0].rstrip('/')
    target_url = f"{clean_url}/search/auction/product?p=å¹å˜´"

    try:
        driver = get_driver()
        log("ğŸ“± å•Ÿå‹• iPhone æ¨¡å¼æ½›å…¥èª¿æŸ¥...")
        driver.get(target_url)
        
        # å¢åŠ éš¨æ©Ÿç­‰å¾…
        wait_time = random.randint(15, 20)
        log(f"â³ ç­‰å¾…è¡Œå‹•ç‰ˆç¶²é æ¸²æŸ“ ({wait_time}s)...")
        time.sleep(wait_time)

        # å¤šæ¬¡å°å¹…æ»‘å‹•
        for _ in range(3):
            driver.execute_script("window.scrollBy(0, 400);")
            time.sleep(2)

        source = driver.page_source
        log(f"ğŸ“¦ åŸå§‹ç¢¼é•·åº¦: {len(source)} å­—å…ƒ")

        # è¡Œå‹•ç‰ˆç¶²é é€šå¸¸ä½¿ç”¨ [class*="ProductItem"] æˆ– [data-testid]
        # ä½¿ç”¨å»£åŸŸæ¢é‡å°‹æ‰¾åŒ…å«åƒ¹æ ¼çš„å•†å“å¡Š
        containers = driver.find_elements(By.XPATH, "//li | //div[contains(@class, 'Item')] | //div[contains(@class, 'Product')]")
        
        log(f"ğŸ” åµæ¸¬åˆ° {len(containers)} å€‹æ½›åœ¨å•†å“å€å¡Š")

        brand_list = ["Selmer", "Vandoren", "Yanagisawa", "Meyer", "Yamaha", "Otto Link", "Beechler", "JodyJazz"]

        for el in containers:
            try:
                txt = el.text.replace("\n", " ").strip()
                if "$" in txt and len(txt) > 10:
                    # æŠ“å–æ¨™é¡Œ (å˜—è©¦å°‹æ‰¾ A æ¨™ç±¤æˆ–ç›´æ¥å–å‰ 50 å­—)
                    try:
                        title = el.find_element(By.XPATH, ".//a").get_attribute("title") or el.text.split("$")[0].strip()
                    except:
                        title = txt.split("$")[0].strip()
                    
                    if len(title) < 4: continue

                    # æŠ“å–åƒ¹æ ¼
                    p_match = re.search(r'\$\s*[0-9,]+', txt)
                    price = p_match.group() if p_match else "N/A"
                    
                    brand = "å…¶ä»–"
                    for b in brand_list:
                        if b.lower() in title.lower():
                            brand = b
                            break
                    
                    all_items.append({
                        "å“ç‰Œ": brand,
                        "å•†å“è³‡è¨Š": title,
                        "å”®åƒ¹": price,
                        "ç¶²å€": target_url
                    })
            except: continue

        df = pd.DataFrame(all_items).drop_duplicates(subset=['å•†å“è³‡è¨Š'])
        log(f"âœ… æˆåŠŸæå– {len(df)} ç­†æ•¸æ“š")
        driver.quit()
        return df
        
    except Exception as e:
        log(f"âŒ åš´é‡ç•°å¸¸: {str(e)}")
        if 'driver' in locals(): driver.quit()
        return pd.DataFrame()

# --- UI ä»‹é¢ ---
st.title("ğŸ· å¹å˜´èª¿æŸ¥ï¼šè¡Œå‹•ç‰ˆå½è£ç³»çµ±")
st.info("ğŸ’¡ é€éæ¨¡æ“¬ iPhone è¡Œå‹•ç‰ˆç¶²é ï¼Œå˜—è©¦é¿é–‹æ¡Œæ©Ÿç‰ˆçš„ IP å°é–ã€‚")

default_store = "https://tw.bid.yahoo.com/booth/Y9133606367"
store_url = st.text_input("åº—å®¶ç¶²å€ï¼š", value=default_store)

if st.button("ğŸš€ å•Ÿå‹•è¡Œå‹•ç‰ˆå½è£æƒæ"):
    if store_url:
        results = scrape_mobile_attempt(store_url)
        if not results.empty:
            st.dataframe(results, use_container_width=True)
            output = BytesIO()
            with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                results.to_excel(writer, index=False)
            st.download_button("ğŸ“¥ ä¸‹è¼‰å ±å‘Š", output.getvalue(), "mobile_sax_report.xlsx")
        else:
            st.error("æƒæå¤±æ•—ã€‚é€™ä»£è¡¨ Yahoo å·²å°è©²ä¼ºæœå™¨ IP é€²è¡Œå…¨ç«™å±è”½ã€‚")
