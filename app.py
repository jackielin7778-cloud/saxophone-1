import streamlit as st
import pandas as pd
import time
import random
import re
import os
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from io import BytesIO

# --- é é¢é…ç½® ---
st.set_page_config(page_title="ğŸ· å¹å˜´èª¿æŸ¥ï¼šé›²ç«¯ç”Ÿå­˜ç‰ˆ", layout="wide")

def get_driver():
    chrome_options = Options()
    # ä½¿ç”¨æœ€æ–°ç„¡é ­æ¨¡å¼
    chrome_options.add_argument("--headless=new")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--disable-gpu")
    
    # æ¨¡æ“¬ iPhone è¡Œå‹•ç‰ˆä»¥é™ä½é˜²ç«ç‰†æˆ’å¿ƒ
    mobile_ua = "Mozilla/5.0 (iPhone; CPU iPhone OS 16_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.6 Mobile/15E148 Safari/604.1"
    chrome_options.add_argument(f"user-agent={mobile_ua}")
    chrome_options.add_argument("--window-size=390,844") 
    
    # éš±è—è‡ªå‹•åŒ–ç‰¹å¾µ
    chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
    chrome_options.add_experimental_option('useAutomationExtension', False)
    chrome_options.add_argument("--disable-blink-features=AutomationControlled")

    # è¨­å®š Streamlit Cloud ä¸Šçš„ Chrome è·¯å¾‘
    for path in ["/usr/bin/chromium", "/usr/bin/chromium-browser"]:
        if os.path.exists(path):
            chrome_options.binary_location = path
            break
            
    service = Service("/usr/bin/chromedriver") if os.path.exists("/usr/bin/chromedriver") else Service()
    driver = webdriver.Chrome(service=service, options=chrome_options)
    
    # é¡å¤– JS æ³¨å…¥æŠ¹é™¤ç‰¹å¾µ
    driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
    return driver

def scrape_store_mouthpiece(base_url):
    all_items = []
    log_area = st.empty()
    
    # å¼·åˆ¶è½‰æ›æˆè©²åº—å®¶çš„ã€Œå¹å˜´ã€æœå°‹çµæœé 
    clean_url = base_url.split('?')[0].rstrip('/')
    target_url = f"{clean_url}/search/auction/product?p=å¹å˜´"

    try:
        driver = get_driver()
        log_area.code(f"ğŸ“¡ æ­£åœ¨å˜—è©¦ç©¿é€ Yahoo é˜²ç«ç‰†... (ç›®æ¨™: {target_url})")
        driver.get(target_url)
        
        # é›²ç«¯ç’°å¢ƒéœ€è¦è¼ƒé•·ç­‰å¾…æ™‚é–“
        time.sleep(random.randint(15, 20))

        # æ¨¡æ“¬æ»¾å‹•
        driver.execute_script("window.scrollBy(0, 600);")
        time.sleep(2)

        source = driver.page_source
        source_len = len(source)
        
        if source_len < 40000:
            st.warning(f"âš ï¸ åŸå§‹ç¢¼é•·åº¦åƒ… {source_len} å­—å…ƒï¼Œå¯èƒ½ä»è¢«é˜»æ“‹ä¸­ã€‚")
        
        # å°‹æ‰¾å•†å“å®¹å™¨ (é‡å°è¡Œå‹•ç‰ˆèˆ‡åº—å®¶ç‰ˆçš„å¤šé‡æ¢é‡)
        containers = driver.find_elements(By.CSS_SELECTOR, 'li[data-item-id], [class*="Item__itemContainer"], [class*="BaseItem"]')
        
        brand_list = ["Selmer", "Vandoren", "Yanagisawa", "Meyer", "Yamaha", "Otto Link", "Beechler", "JodyJazz"]

        for el in containers:
            try:
                full_text = el.text.strip().replace("\n", " ")
                if "$" in full_text:
                    # æŠ“å–æ¨™é¡Œ (å˜—è©¦å¾ a æ¨™ç±¤æˆ–æ–‡å­—å‰åŠæ®µ)
                    title = full_text.split("$")[0].strip()[:60]
                    
                    # æŠ“å–åƒ¹æ ¼
                    p_match = re.search(r'\$\s*[0-9,]+', full_text)
                    price = p_match.group() if p_match else "N/A"
                    
                    # å“ç‰Œåˆ¤æ–·
                    brand = "å…¶ä»–"
                    for b in brand_list:
                        if b.lower() in title.lower():
                            brand = b
                            break
                    
                    all_items.append({
                        "å“ç‰Œ": brand,
                        "å•†å“è³‡è¨Š": title,
                        "å”®åƒ¹": price
                    })
            except:
                continue

        driver.quit()
        df = pd.DataFrame(all_items).drop_duplicates(subset=['å•†å“è³‡è¨Š'])
        return df

    except Exception as e:
        st.error(f"âŒ ç™¼ç”Ÿç•°å¸¸: {str(e)}")
        if 'driver' in locals(): driver.quit()
        return pd.DataFrame()

# --- ä»‹é¢ ---
st.title("ğŸ· è–©å…‹æ–¯é¢¨å¹å˜´ï¼šåº—å®¶åº—å…§èª¿æŸ¥å™¨")
st.info("ğŸ’¡ æ­¤å·¥å…·æœƒè‡ªå‹•åœ¨åº—å®¶å…§æœå°‹ã€Œå¹å˜´ã€é—œéµå­—ã€‚")

store_url = st.text_input("è«‹è¼¸å…¥åº—å®¶é¦–é ç¶²å€ï¼š", value="https://tw.bid.yahoo.com/booth/Y9133606367")

if st.button("ğŸš€ åŸ·è¡Œèª¿æŸ¥"):
    if store_url:
        with st.spinner("æ­£åœ¨æŠ“å–æ•¸æ“šï¼Œè«‹ç¨å€™..."):
            results = scrape_store_mouthpiece(store_url)
            
        if not results.empty:
            st.success(f"æˆåŠŸæ‹”å› {len(results)} ç­†æ•¸æ“šï¼")
            st.dataframe(results, use_container_width=True)
            
            # Excel ä¸‹è¼‰
            output = BytesIO()
            with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                results.to_excel(writer, index=False)
            st.download_button("ğŸ“¥ ä¸‹è¼‰ Excel èª¿æŸ¥å ±å‘Š", output.getvalue(), "sax_report.xlsx")
        else:
            st.error("ç›®å‰æŠ“ä¸åˆ°ä»»ä½•æ•¸æ“šã€‚é€™ä»£è¡¨é›²ç«¯ IP ä»è¢« Yahoo å°é–ï¼Œæˆ–æ˜¯è©²åº—å®¶å…§ç„¡ã€å¹å˜´ã€é—œéµå­—å•†å“ã€‚")
