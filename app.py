# 1. å®‰è£å¿…è¦å¥—ä»¶ (Colab ç’°å¢ƒå°ˆç”¨)
!pip install selenium pandas xlsxwriter
!apt-get update
!apt-get install -y chromium-chromedriver

import pandas as pd
import time
import re
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By

# 2. è¨­å®šç€è¦½å™¨
def get_colab_driver():
    options = Options()
    options.add_argument('--headless')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36")
    service = Service('/usr/bin/chromedriver')
    driver = webdriver.Chrome(service=service, options=options)
    return driver

# 3. åŸ·è¡Œçˆ¬å–
def scrape_yahoo_store(store_url):
    target_url = store_url.split('?')[0].rstrip('/') + "/search/auction/product?p=å¹å˜´"
    driver = get_colab_driver()
    print(f"ğŸš€ æ­£åœ¨é€é Google ä¼ºæœå™¨æ½›å…¥: {target_url}")
    
    driver.get(target_url)
    time.sleep(15) # çµ¦äºˆå……è¶³åŠ è¼‰æ™‚é–“
    
    # æ»¾å‹•
    driver.execute_script("window.scrollTo(0, 2000);")
    time.sleep(3)

    items = driver.find_elements(By.CSS_SELECTOR, 'li[data-item-id], [class*="Item__itemContainer"], [class*="BaseItem"]')
    print(f"ğŸ“¦ åµæ¸¬åˆ° {len(items)} å€‹å€å¡Šï¼Œé–‹å§‹æå–...")

    all_data = []
    brand_list = ["Selmer", "Vandoren", "Yanagisawa", "Meyer", "Yamaha", "Otto Link", "Beechler", "JodyJazz"]

    for el in items:
        try:
            txt = el.text.replace("\n", " ")
            if "$" in txt:
                p_match = re.search(r'\$\s*[0-9,]+', txt)
                price = p_match.group() if p_match else "N/A"
                title = txt.split("$")[0].strip()[:60]
                
                brand = "å…¶ä»–"
                for b in brand_list:
                    if b.lower() in title.lower():
                        brand = b
                        break
                
                all_data.append({"å“ç‰Œ": brand, "å•†å“è³‡è¨Š": title, "å”®åƒ¹": price})
        except: continue

    driver.quit()
    df = pd.DataFrame(all_data).drop_duplicates()
    return df

# --- åŸ·è¡Œè™• ---
url = "https://tw.bid.yahoo.com/booth/Y9133606367" # ä½ å¯ä»¥æ›æˆä»»ä½•åº—å®¶
result_df = scrape_yahoo_store(url)

if not result_df.empty:
    print("âœ… æˆåŠŸæ‹”å›æ•¸æ“šï¼")
    display(result_df)
    result_df.to_excel("sax_report.xlsx", index=False)
    print("ğŸ“ Excel å·²å­˜æª”ï¼Œè«‹é»é¸å·¦å´è³‡æ–™å¤¾åœ–ç¤ºä¸‹è¼‰ã€‚")
else:
    print("âŒ Google IP ä¹Ÿè¢«æ“‹äº†ï¼Œè«‹å˜—è©¦æ›´æ› Colab çš„é‹è¡Œéšæ®µï¼ˆé‡æ–°é€£ç·šï¼‰ã€‚")
